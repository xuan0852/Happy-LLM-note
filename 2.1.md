## 2.1注意力机制
### 2.2.1什么是注意力机制
神经网络核心架构：
·前馈神经网络（FNN），即每⼀层的神经元都和上下两层的每⼀个神经元完全连接
·卷积神经网络（CNN），即训练参数量远⼩于前馈神经⽹络的卷积层来进⾏特征提取和学习
·循环神经网络（RNN），能够使⽤历史信息作为输⼊、包含环和⾃重复的⽹络

其中专用于处理序列、时序数据的RNN能够在NLP任务上取得最优成果。存在缺陷：
1.序列依序计算限制了计算机并行计算的能力。
2.RNN难以捕捉长序列的相关关系。

什么是注意力机制？
在⾃然语⾔处理领域，我们可以通过将重点注意⼒集中在⼀个或⼏个 token，从⽽取得更⾼效⾼质的计算效果。

注意力机制三个核心变量：Query(查询值)、Key(键值)、Value(真值)。
注意⼒机制的特点是通过计算 Query 与Key的相关性为真值加权求和，从⽽拟合序列中每个词同其他词的相关关系。