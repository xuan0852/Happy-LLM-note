## 2.3 Build Transformer
### 2.3.1 Embedding层
功能：将⾃然语⾔的输⼊转化为机器可以处理的向量。
在输⼊神经⽹络之前，我们往往会先让⾃然语⾔输⼊通过分词器 tokenizer，分词器的作⽤是把⾃然语⾔输⼊切分成 token 并转化成⼀个固定的 index。
形状：，Embedding 层的输⼊往往是⼀个形状为 （batch_size，seq_len，1）的矩阵，第⼀个维度是⼀次批处理的数量，第⼆个维度是⾃然语⾔序列的
⻓度，第三个维度则是 token 经过 tokenizer 转化成的 index 值。
### 2.3.2 位置编码
功能：为使⽤序列顺序信息，保留序列中的相对位置
信息，Transformer 采⽤了位置编码机制。
位置编码，即根据序列中 token 的相对位置对其进⾏编码，再将位置编码加⼊词向量编码中。
好处：
1.使 PE 能够适应⽐训练集⾥⾯所有句⼦更⻓的句⼦
2.可以让模型容易地计算出相对位置
### 2.3.3完整的Transformer
![alt text](image-1.png)